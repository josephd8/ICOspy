{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.northwestern.edu/brand/images/wordmark/wordmark-vert.gif\" alt=\"Northwestern Logo\" width=\"500\" align=\"left\">\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `src.generate_features.drop_na()` funtion with arguments and keyword arguments given as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:58.236244Z",
     "start_time": "2019-05-12T22:52:56.595862Z"
    }
   },
   "outputs": [],
   "source": [
    "# must go first\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# Reloads functions each time so you can edit a script \n",
    "# and not need to restart the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# plotting\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"poster\", font_scale=1.3)\n",
    "import folium\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "sns.set()\n",
    "sns.set_context('poster', font_scale=1.3)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging \n",
    "\n",
    "# basic wrangling\n",
    "import numpy as np\n",
    "import yaml\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# eda tools\n",
    "import pivottablejs\n",
    "import missingno as msno\n",
    "\n",
    "# Update matplotlib defaults to something nicer\n",
    "mpl_update = {\n",
    "    'font.size': 16,\n",
    "    'xtick.labelsize': 14,\n",
    "    'ytick.labelsize': 14,\n",
    "    'figure.figsize': [12.0, 8.0],\n",
    "    'axes.labelsize': 20,\n",
    "    'axes.labelcolor': '#677385',\n",
    "    'axes.titlesize': 20,\n",
    "    'lines.color': '#0055A7',\n",
    "    'lines.linewidth': 3,\n",
    "    'text.color': '#677385',\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': 'Tahoma'\n",
    "}\n",
    "mpl.rcParams.update(mpl_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:58.279542Z",
     "start_time": "2019-05-12T22:52:58.238334Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create helper functions for specifying paths and appending\n",
    "# directories with relevant python source code.\n",
    "# This is a lot at the top of your notebook but if you get the jupyter\n",
    "# extension for collapsing headings, you can always have this and the\n",
    "# imports collapsed\n",
    "\n",
    "root_dir = os.curdir\n",
    "max_nest = 10  # arbitrary, 3 would probably suffice\n",
    "nest = 0\n",
    "while \"src\" not in os.listdir(root_dir) and nest < max_nest:\n",
    "    # Look up the directory structure for a src directory\n",
    "    root_dir = os.path.join(os.pardir, root_dir)\n",
    "    nest += 1\n",
    "    \n",
    "# If you don't find the src directory, the root directory is this directory\n",
    "root_dir = os.path.abspath(root_dir) if nest < max_nest else os.path.abspath(\n",
    "    os.curdir)\n",
    "\n",
    "# Add the root directory to be able to import from src, etc\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "# Get the source directory and append path to access\n",
    "# python packages/scripts within directory\n",
    "if \"src\" in os.listdir(root_dir):\n",
    "    src_dir = os.path.join(root_dir, \"src\")\n",
    "\n",
    "# If data or figures directory don't exist in project directory,\n",
    "# they will be saved to this directory\n",
    "data_dir = os.path.join(\n",
    "    root_dir, \"data\") if \"data\" in os.listdir(root_dir) else os.curdir\n",
    "external_data_dir = os.path.join(\n",
    "    data_dir, \"external\") if \"external\" in os.listdir(data_dir) else os.curdir\n",
    "figure_dir = os.path.join(\n",
    "    root_dir,\n",
    "    \"figures\") if \"figures\" in os.listdir(root_dir) else os.curdir\n",
    "models_dir = os.path.join(\n",
    "    root_dir,\n",
    "    \"models\") if \"models\" in os.listdir(root_dir) else os.curdir\n",
    "config_dir = os.path.join(\n",
    "    root_dir,\n",
    "    \"config\") if \"config\" in os.listdir(root_dir) else os.curdir\n",
    "\n",
    "# Prepends the directory path for specifying paths to data or figures\n",
    "# dataplus(\"data.csv\") -> \"/Users/cmawer/project/data/data.csv\"\n",
    "# figplus(\"cool.png\") -> \"/Users/cmawer/project/figures/cool.png\"\n",
    "dataplus = lambda x: os.path.join(data_dir, x)\n",
    "dataextplus = lambda x: os.path.join(external_data_dir, x)\n",
    "figplus = lambda x: os.path.join(figure_dir, x)\n",
    "modelsplus = lambda x: os.path.join(models_dir, x)\n",
    "configplus = lambda x: os.path.join(config_dir, x)\n",
    "\n",
    "# Prepends the date to a string (e.g. to save dated files)\n",
    "# dateplus(\"cool-figure.png\") -> \"2018-12-05-cool-figure.png\"\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "dateplus = lambda x: \"%s-%s\" % (now, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:58.610349Z",
     "start_time": "2019-05-12T22:52:58.281097Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import from project src \n",
    "from src import load_data as ld\n",
    "from src import generate_features as gf \n",
    "from src.helpers.helpers import Timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load config YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:58.654033Z",
     "start_time": "2019-05-12T22:52:58.613050Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(configplus(\"test_model_config.yml\"), \"r\") as f:\n",
    "    config = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:58.689570Z",
     "start_time": "2019-05-12T22:52:58.656277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'load_data', 'generate_features', 'train_model', 'score_model', 'evaluate_model'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:58.870650Z",
     "start_time": "2019-05-12T22:52:58.691161Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataplus(\"sample/music_data_combined.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:58.938920Z",
     "start_time": "2019-05-12T22:52:58.872286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist.hotttnesss</th>\n",
       "      <th>artist.id</th>\n",
       "      <th>artist.name</th>\n",
       "      <th>artist_mbtags</th>\n",
       "      <th>artist_mbtags_count</th>\n",
       "      <th>bars_confidence</th>\n",
       "      <th>bars_start</th>\n",
       "      <th>beats_confidence</th>\n",
       "      <th>beats_start</th>\n",
       "      <th>duration</th>\n",
       "      <th>...</th>\n",
       "      <th>start_of_fade_out</th>\n",
       "      <th>tatums_confidence</th>\n",
       "      <th>tatums_start</th>\n",
       "      <th>tempo</th>\n",
       "      <th>terms</th>\n",
       "      <th>terms_freq</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>time_signature_confidence</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.401998</td>\n",
       "      <td>ARD7TVE1187B99BFB1</td>\n",
       "      <td>Casual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.58521</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.58521</td>\n",
       "      <td>218.93179</td>\n",
       "      <td>...</td>\n",
       "      <td>218.932</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.28519</td>\n",
       "      <td>92.198</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>I Didn't Mean To</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.417500</td>\n",
       "      <td>ARMJAGH1187FB546F3</td>\n",
       "      <td>The Box Tops</td>\n",
       "      <td>classic pop and rock</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.71054</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.20627</td>\n",
       "      <td>148.03546</td>\n",
       "      <td>...</td>\n",
       "      <td>137.915</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.20627</td>\n",
       "      <td>121.274</td>\n",
       "      <td>blue-eyed soul</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.384</td>\n",
       "      <td>Soul Deep</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.343428</td>\n",
       "      <td>ARKRRTF1187B9984DA</td>\n",
       "      <td>Sonora Santanera</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.73152</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.73152</td>\n",
       "      <td>177.47546</td>\n",
       "      <td>...</td>\n",
       "      <td>172.304</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.42132</td>\n",
       "      <td>100.070</td>\n",
       "      <td>salsa</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Amor De Cabaret</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.454231</td>\n",
       "      <td>AR7G5I41187FB4CE6C</td>\n",
       "      <td>Adam Ant</td>\n",
       "      <td>uk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.30621</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.81002</td>\n",
       "      <td>233.40363</td>\n",
       "      <td>...</td>\n",
       "      <td>217.124</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.56254</td>\n",
       "      <td>119.293</td>\n",
       "      <td>pop rock</td>\n",
       "      <td>0.988584</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Something Girls</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.401724</td>\n",
       "      <td>ARXR32B1187FB57099</td>\n",
       "      <td>Gob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.06368</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.13576</td>\n",
       "      <td>209.60608</td>\n",
       "      <td>...</td>\n",
       "      <td>198.699</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.13576</td>\n",
       "      <td>129.738</td>\n",
       "      <td>pop punk</td>\n",
       "      <td>0.887288</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.562</td>\n",
       "      <td>Face the Ashes</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist.hotttnesss           artist.id       artist.name  \\\n",
       "0           0.401998  ARD7TVE1187B99BFB1            Casual   \n",
       "1           0.417500  ARMJAGH1187FB546F3      The Box Tops   \n",
       "2           0.343428  ARKRRTF1187B9984DA  Sonora Santanera   \n",
       "3           0.454231  AR7G5I41187FB4CE6C          Adam Ant   \n",
       "4           0.401724  ARXR32B1187FB57099               Gob   \n",
       "\n",
       "          artist_mbtags  artist_mbtags_count  bars_confidence  bars_start  \\\n",
       "0                   NaN                  0.0            0.643     0.58521   \n",
       "1  classic pop and rock                  1.0            0.007     0.71054   \n",
       "2                   NaN                  0.0            0.980     0.73152   \n",
       "3                    uk                  1.0            0.017     1.30621   \n",
       "4                   NaN                  0.0            0.175     1.06368   \n",
       "\n",
       "   beats_confidence  beats_start   duration  ...   start_of_fade_out  \\\n",
       "0             0.834      0.58521  218.93179  ...             218.932   \n",
       "1             1.000      0.20627  148.03546  ...             137.915   \n",
       "2             0.980      0.73152  177.47546  ...             172.304   \n",
       "3             0.809      0.81002  233.40363  ...             217.124   \n",
       "4             0.883      0.13576  209.60608  ...             198.699   \n",
       "\n",
       "   tatums_confidence  tatums_start    tempo           terms terms_freq  \\\n",
       "0              0.779       0.28519   92.198         hip hop   1.000000   \n",
       "1              0.969       0.20627  121.274  blue-eyed soul   1.000000   \n",
       "2              0.482       0.42132  100.070           salsa   1.000000   \n",
       "3              0.601       0.56254  119.293        pop rock   0.988584   \n",
       "4              1.000       0.13576  129.738        pop punk   0.887288   \n",
       "\n",
       "   time_signature  time_signature_confidence             title  year  \n",
       "0             4.0                      0.778  I Didn't Mean To     0  \n",
       "1             4.0                      0.384         Soul Deep  1969  \n",
       "2             1.0                      0.000   Amor De Cabaret     0  \n",
       "3             4.0                      0.000   Something Girls  1982  \n",
       "4             4.0                      0.562    Face the Ashes  2007  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `generate features.drop_na()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:58.977021Z",
     "start_time": "2019-05-12T22:52:58.940808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'make_categorical': {'columns': 'terms',\n",
       "  'terms': {'load_column_as_list': {'path': 'data/auxiliary/genres.csv',\n",
       "    'header': None,\n",
       "    'column': 0},\n",
       "   'one_hot_encode': True}},\n",
       " 'bin_values': {'columns': ['key', 'artist.hotttnesss'], 'quartiles': [4, 2]},\n",
       " 'drop_na': {'columns': 'song.hotttnesss'},\n",
       " 'choose_features': {'features_to_use': ['key',\n",
       "   'beats_start',\n",
       "   'bars_start',\n",
       "   'duration',\n",
       "   'terms',\n",
       "   'loudness'],\n",
       "  'target': 'song.hotttnesss'},\n",
       " 'save_features': 'test/model/test/music_processed.csv'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"generate_features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:59.016377Z",
     "start_time": "2019-05-12T22:52:58.978439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': 'song.hotttnesss'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"generate_features\"][\"drop_na\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:59.060763Z",
     "start_time": "2019-05-12T22:52:59.018233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function drop_na in module src.generate_features:\n",
      "\n",
      "drop_na(df, columns=None)\n",
      "    Drops rows of dataframe where there are null values in the columns given.\n",
      "    \n",
      "    Args:\n",
      "        df (:py:class:`pandas.DataFrame`): DataFrame containing data\n",
      "        columns (str or list of str, optional): Name of column or list of columns for which to drop rows\n",
      "            that contain nulls. If None, the original dataframe will be returned.\n",
      "    \n",
      "    Returns:\n",
      "        df (:py:class:`pandas.DataFrame`): DataFrame containing only data for which no nulls existed in the columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gf.drop_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Providing the `columns` argument directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:59.109560Z",
     "start_time": "2019-05-12T22:52:59.062870Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4351 values were dropped from the dataset because of missing values\n"
     ]
    }
   ],
   "source": [
    "dfA = gf.drop_na(df, columns=\"song.hotttnesss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we provide the dictionary containing the arguments for `generate_features.drop_na()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:59.159639Z",
     "start_time": "2019-05-12T22:52:59.111693Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4351 values were dropped from the dataset because of missing values\n"
     ]
    }
   ],
   "source": [
    "dfB = gf.drop_na(df, **config[\"generate_features\"][\"drop_na\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:59.201299Z",
     "start_time": "2019-05-12T22:52:59.161170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfB.equals(dfA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works! That's because\n",
    "\n",
    "```python\n",
    "dfB = gf.drop_na(df, **config[\"generate_features\"][\"drop_na\"])\n",
    "```\n",
    "\n",
    "is equivalent to executing\n",
    "\n",
    "```python\n",
    "dfB = gf.drop_na(df, columns=\"song.hotttnesss\")\n",
    "```\n",
    "\n",
    "The `y = func(x, **dictionary)` pattern expands each key into the argument as if you were to write `key=val`. \n",
    "\n",
    "So for \n",
    "\n",
    "```python\n",
    "dictionary = {\"key1\": \"val1\", \"key2\", \"val2\", \"key3\": \"val3\"}\n",
    "```\n",
    "\n",
    "executing `y = func(x, **dictionary)` is the same as: \n",
    "\n",
    "```python\n",
    "y = func(x, key1=val1, key3=val3, key2=val2)\n",
    "```\n",
    "\n",
    "(or any ordering of `key1`, `key2`, and `key3`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if `columns` wasn't a keyword argument ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:59.244505Z",
     "start_time": "2019-05-12T22:52:59.203454Z"
    }
   },
   "outputs": [],
   "source": [
    "def drop_na_test(df, columns):\n",
    "    \"\"\"Drops rows of dataframe where there are null values in the columns given.\n",
    "\n",
    "    Args:\n",
    "        df (:py:class:`pandas.DataFrame`): DataFrame containing data\n",
    "        columns (str or list of str): Name of column or list of columns for which to drop rows that contain nulls.\n",
    "\n",
    "    Returns:\n",
    "        df (:py:class:`pandas.DataFrame`): DataFrame containing only data for which no nulls existed in the columns\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    if columns is not None:\n",
    "        columns = [columns] if type(columns) == str else columns\n",
    "        num_nas = df[columns].isna().sum()\n",
    "        for col in columns:\n",
    "            logger.info(\"There were %i missing %s values\", num_nas.loc[col],\n",
    "                        col)\n",
    "        df_len = len(df)\n",
    "        df = df.dropna(subset=columns)\n",
    "        logger.warning(\n",
    "            \"%i values were dropped from the dataset because of missing values\",\n",
    "            df_len - len(df))\n",
    "    else:\n",
    "        logger.warning(\n",
    "            \"No columns provided for drop_na, original dataframe being returned\"\n",
    "        )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:59.295211Z",
     "start_time": "2019-05-12T22:52:59.246164Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4351 values were dropped from the dataset because of missing values\n"
     ]
    }
   ],
   "source": [
    "dfC = drop_na_test(df, **config[\"generate_features\"][\"drop_na\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:59.345254Z",
     "start_time": "2019-05-12T22:52:59.297297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfC.equals(dfB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as all required arguments exist in the dictionary that is expanded in the function, the function will work as desired.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why not use `**kwargs`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:59.395501Z",
     "start_time": "2019-05-12T22:52:59.348014Z"
    }
   },
   "outputs": [],
   "source": [
    "def drop_na_testB(df, **kwargs):\n",
    "    \"\"\"Drops rows of dataframe where there are null values in the columns given.\n",
    "\n",
    "    Args:\n",
    "        df (:py:class:`pandas.DataFrame`): DataFrame containing data\n",
    "        **kwargs: Should include `columns`\n",
    "\n",
    "    Returns:\n",
    "        df (:py:class:`pandas.DataFrame`): DataFrame containing only data for which no nulls existed in the columns\n",
    "    \"\"\"\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "    if columns is not None:\n",
    "        columns = [columns] if type(columns) == str else columns\n",
    "        num_nas = df[columns].isna().sum()\n",
    "        for col in columns:\n",
    "            logger.info(\"There were %i missing %s values\", num_nas.loc[col],\n",
    "                        col)\n",
    "        df_len = len(df)\n",
    "        df = df.dropna(subset=columns)\n",
    "        logger.warning(\n",
    "            \"%i values were dropped from the dataset because of missing values\",\n",
    "            df_len - len(df))\n",
    "    else:\n",
    "        logger.warning(\n",
    "            \"No columns provided for drop_na, original dataframe being returned\"\n",
    "        )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:52:59.708273Z",
     "start_time": "2019-05-12T22:52:59.401561Z"
    }
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'columns' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b0225c901b2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrop_na_testB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generate_features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"drop_na\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-893f444e5f89>\u001b[0m in \u001b[0;36mdrop_na_testB\u001b[0;34m(df, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mnum_nas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'columns' referenced before assignment"
     ]
    }
   ],
   "source": [
    "dfD = drop_na_testB(df, **config[\"generate_features\"][\"drop_na\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops, you actually need to pull out `columns` from the `kwargs` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:53:07.359702Z",
     "start_time": "2019-05-12T22:53:07.318265Z"
    }
   },
   "outputs": [],
   "source": [
    "def drop_na_testB(df, **kwargs):\n",
    "    \"\"\"Drops rows of dataframe where there are null values in the columns given.\n",
    "\n",
    "    Args:\n",
    "        df (:py:class:`pandas.DataFrame`): DataFrame containing data\n",
    "        **kwargs: Should include `columns`\n",
    "\n",
    "    Returns:\n",
    "        df (:py:class:`pandas.DataFrame`): DataFrame containing only data for which no nulls existed in the columns\n",
    "    \"\"\"\n",
    "    \n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    columns = kwargs[\"columns\"]\n",
    "    if columns is not None:\n",
    "        columns = [columns] if type(columns) == str else columns\n",
    "        num_nas = df[columns].isna().sum()\n",
    "        for col in columns:\n",
    "            logger.info(\"There were %i missing %s values\", num_nas.loc[col],\n",
    "                        col)\n",
    "        df_len = len(df)\n",
    "        df = df.dropna(subset=columns)\n",
    "        logger.warning(\n",
    "            \"%i values were dropped from the dataset because of missing values\",\n",
    "            df_len - len(df))\n",
    "    else:\n",
    "        logger.warning(\n",
    "            \"No columns provided for drop_na, original dataframe being returned\"\n",
    "        )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:53:08.115106Z",
     "start_time": "2019-05-12T22:53:08.069781Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4351 values were dropped from the dataset because of missing values\n"
     ]
    }
   ],
   "source": [
    "dfD = drop_na_testB(df, **config[\"generate_features\"][\"drop_na\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:53:08.923005Z",
     "start_time": "2019-05-12T22:53:08.888910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfD.equals(dfA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are equal but it is not clear to anyone using the function what the expected arguments are and columns has to be pulled out of the `kwargs` dictionary to be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watermark \n",
    "For full reproducibility of results, use exact data extraction as defined at top of notebook and ensure that the environment is exactly as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:53:09.945674Z",
     "start_time": "2019-05-12T22:53:09.862193Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json        2.0.9\n",
      "numpy       1.15.1\n",
      "matplotlib  2.2.3\n",
      "seaborn     0.9.0\n",
      "folium      0.7.0\n",
      "logging     0.5.1.2\n",
      "yaml        3.13\n",
      "re          2.2.1\n",
      "pandas      0.23.4\n",
      "missingno   0.4.1\n",
      "CPython 3.6.7\n",
      "IPython 7.2.0\n",
      "\n",
      "compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)\n",
      "system     : Darwin\n",
      "release    : 18.2.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 12\n",
      "interpreter: 64bit\n",
      "Git hash   : c83a5448fb6bf0d75a7cf573ab3eb359679f93f2\n"
     ]
    }
   ],
   "source": [
    "# ! pip install watermark\n",
    "%load_ext watermark\n",
    "%watermark -v -m --iversions -g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
